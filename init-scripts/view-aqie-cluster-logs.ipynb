{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f406666d-a567-4813-a288-9a0a4e4efc05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# View Farming Stats cluster logs\n",
    "**Author:** Josh Moatt <joshua.moatt@defra.gov.uk>  \n",
    "**Date of last update:** 09/09/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4f30b69-99a0-4b63-ae42-9b82d63b8e22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "We have added logging to the Farming Stats cluster. This is really useful, as it allows us to troubleshoot any failures in the Farming Stats cluster. However, the logs for the cluster are saved to the DBFS and can quickly grow to a huge number of files. There is an automated notebook set up to clean the logs every weekend, removing anything over 28 days old. But that still leaves quite a few logs to deal with. The code below was shared by Cat Hand, and enables users to pull a list of all the logs, ID the log of interest, and then read the log to troubleshoot any issues. \n",
    "\n",
    "\n",
    "The cluster ID for the farming stats cluster is **0313-132909-hsaqokf5**.\n",
    "\n",
    "The cluster logs are saved in the dbfs here: **/dbfs/cluster-logs/0313-132909-hsaqokf5**. There are four directories in this folder:\n",
    "\n",
    "* driver\n",
    "* eventlog\n",
    "* executer\n",
    "* init_scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bba9d407-fcd8-4a0d-89b0-0b5402da4a97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## How to use\n",
    "\n",
    "To use the code, do the following:\n",
    "\n",
    "1. Run the first code chunk. This will output a list of files and the date they were modified. Find the most recent file and copy the file name.\n",
    "2. Paste the file name into the second and third code chunks after **/dbfs/cluster-logs/0313-132909-hsaqokf5/init_scripts/**. \n",
    "3. Now run the second code chunk. In the output, ID the relevant stdout.log and stferr.log files and copy the file names.\n",
    "4. Paste these final names into the third code chunk after the final **/** (and after the code you updated in step 2), then run the thrid code chunk.\n",
    "5. This will output the contents of the log for you to examine. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1db50a96-05c1-4c37-aeb5-5d7140ed9306",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3149dbbb-094c-4cea-b8e4-3076b50144fe",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Find the latest log folder"
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "ls -hlt /dbfs/cluster-logs/0313-132909-hsaqokf5/init_scripts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5dd95012-0e12-48b0-bd67-85b4540dfe78",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "List the saved logs in that folder"
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "ls -hlt /dbfs/cluster-logs/0313-132909-hsaqokf5/init_scripts/0313-132909-hsaqokf5_a8e4e7ec6b79464aa53d83a6ed320174"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7ec2d02-fc56-4117-9f5e-b3a37f704e9d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Display the log"
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "cat /dbfs/cluster-logs/0313-132909-hsaqokf5/init_scripts/0313-132909-hsaqokf5_a8e4e7ec6b79464aa53d83a6ed320174/20250908_050635_00_general-init-script.sh.stdout.log"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1015138514936953,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "view-farming-stats-cluster-logs",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
