{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c4d3176-4f4a-4fef-bf81-690c08036cef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Farming Stats RStudio Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb2a0686-e911-4df4-867f-29a62e3e8753",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Notebook overview\n",
    "This notebook is used to automate turning the Farming Stats Shared RStudio cluster on and off. It is run by to jobs in the databricks workflow. The first job is set up to trun the cluster on at 06:00 every Monday, this should ensure the cluster is back up and running by 07:00 when staff begin to arrive. The second job is set to turn the cluster off again at 19:00 every Friday, when all staff *should* have finished their work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c646f0e9-efc2-45be-b985-c717e34da37e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Key components of the notebook\n",
    "\n",
    "#### Personal Access Token\n",
    "To manage a cluster, you must have a databricks Personal Access Token (PAT). The PAT is stored seperately in a \".env\" file and then pulled into the notebook (see chunk 8). For this notebook, the .env file is stored in Josh Moatt's personal workspace. The .env file specifies the PAT as \"DATABRICKS_TOKEN = my_token\". Keeping the .env file seperate to this repo helps keeps the PAT secure by avoiding it being accessible to everyone and by not keeping it in the git repo. This should not impact the ability of other admins to run the jobs to turn the cluster on and off, cos once the job is created admins can run it as the creator (i.e. Josh) so the job will have the necessary permissions.\n",
    "\n",
    "#### Cluster info\n",
    "For the code to work, you must specify which cluster is to be turned on and off. To do this you specify two variables: \n",
    "\n",
    "* `workspace_url` - the URL for the workspace containing the cluster. This is likely to be the same used as here, as we are all using the UC workspace.\n",
    "\n",
    "* `cluster_id` - the ID of the cluster you want to manage. This can be found from the URL of the cluster with the text coming after\"cluster/\". e.g. if the url is \"https://adb-2353967604677522.2.azuredatabricks.net/compute/clusters/0000-123456-abcdefg1?o=2353967604677522\" then the cluster ID is \"0000-123456-abcdefg1\".\n",
    "\n",
    "#### Parameters\n",
    "The parameter controlling the code is `task` - set in block 10. The default value for `task` is \"turn_on\", which cause the function `w.cluster.start` to be run, which will turn on the cluster (see block 12). When `task` is set to \"turn_off\" the function `w.clusters.delete` will be run, which turns the cluster off (see block 12). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "842afe01-b4a1-463a-81c0-dbb2ee3d0e34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### How the notebook runs\n",
    "The notebook uses python and is paramterised to execute code depending on which job is being run. The steps of the notebook are as follows:\n",
    "\n",
    "1. install dotenv\n",
    "2. import packages/functions\n",
    "3. read in PAT and assign to `token`\n",
    "4. set `workspace_url` and `cluster_id`\n",
    "5. set parameters to `task`. Default is \"turn_on\", alternative is \"turn_off\"\n",
    "6. access workspace/cluster\n",
    "7. execute code depending on `task`.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38c2b29a-83ad-4fb7-a73a-fdc31ae8dd4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Automating notebook through a job\n",
    "To automate the execution of this code, the notebook is run through a job using databricks workflows. It uses two seperate jobs, one to turn on the cluster and on to turn off the cluster, how the code is executed depends on the paramters `task` which can be se in the job. \n",
    "\n",
    "To set up the job to run this notebook, you do the following:\n",
    "\n",
    "1. In databricks, got to workflows in the left hand menu.\n",
    "2. Click the blue \"Create job\" button in the top right corner.\n",
    "3. At the top right of the screen, where it says \"New Job....\", click to edit the job title - this is the job will appear in the jobs list. \n",
    "4. In the \"Task name\" box, add your taks name (best practice is to use snake case e.g. \"turn_on_cluster\")\n",
    "5. In the \"Path\" box, insert the full path to your notebook (e.g. \"/Workspace/farming_stats/config/farming-stats-cluster-management/farming-stats-rstudio-cluster\").\n",
    "6. Ensure \"compute\" is set to Serverless.\n",
    "7. If creating a job to turn the cluster on, the default parameter value is \"turn_on\" so you can skip this step. If creating a job to turn the cluster off, click the blue \"+ add\" button next to parameters. In \"Key\" enter the name of your parameter variable - \"task\". In value enter your parameter value - \"turn_off\".\n",
    "8. Click the blue \"create task\" button.\n",
    "9. Under \"Schedules & Triggers\" on the right hand panel, click \"Add trigger\", if prompted to save the job, do so. \n",
    "10. In the drop down that appears, select \"Scheduled\" then \"Advanced\". You can now set this to execute the code whenever you desire, e.g. every Week on Monday at 06:00 etc. Once happy click the blue \"Save\" button. \n",
    "11. Under \"Job notification\" click edit notifications. You can use this to set up the email alerts you want to recieve - I went for alerts **if** the code fails to run. \n",
    "12. Save the job. If you want to test it, you can always click the blue \"run now\" button in the top right (it's a good idea to test these when convenient).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a527c18f-afc9-4dbc-bd70-b0b033073b9d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "install dotenv"
    }
   },
   "outputs": [],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e3d0c81-72fa-4048-b349-a1f57d251667",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "import packages"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff59c1d4-367d-42d3-b72b-a30ad82c09b4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "pull PAT"
    }
   },
   "outputs": [],
   "source": [
    "# read .env file\n",
    "_ = load_dotenv(\"/Workspace/Users/joshua.moatt@defra.gov.uk/admin/.env\")\n",
    "\n",
    "# pull my token \n",
    "token = os.getenv('DATABRICKS_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "064984da-02ff-444d-a44f-c7248e6d96c2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "set workspace details and parameters"
    }
   },
   "outputs": [],
   "source": [
    "# workspace URL\n",
    "workspace_url = \"https://adb-2353967604677522.2.azuredatabricks.net\"\n",
    "\n",
    "# cluster ID\n",
    "cluster_id = \"0313-132909-hsaqokf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfe62e8f-2405-4643-8c8b-f8ef56f23746",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "set parameters"
    }
   },
   "outputs": [],
   "source": [
    "# create parameter\n",
    "dbutils.widgets.text(\"task\", \"turn_on\")\n",
    "\n",
    "# assign parameter to task\n",
    "task = dbutils.widgets.get(\"task\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cfb90c3-1e9b-41ba-bee3-665d7d5dcd77",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "access workspace"
    }
   },
   "outputs": [],
   "source": [
    "w = WorkspaceClient(\n",
    "    host = workspace_url,\n",
    "    token = token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4e2499d-12de-4145-a12f-c0df229e113e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "task: turn on and off"
    }
   },
   "outputs": [],
   "source": [
    "if task == \"turn_on\":\n",
    "    w.clusters.start(cluster_id = cluster_id)\n",
    "elif task == \"turn_off\":\n",
    "    w.clusters.delete(cluster_id = cluster_id)\n",
    "else:\n",
    "    print(\"Invalid task\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "farming-stats-rstudio-cluster",
   "widgets": {
    "task": {
     "currentValue": "turn_on",
     "nuid": "7e534d88-a83c-4419-b5e3-7c9c6d954d68",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "turn_on",
      "label": null,
      "name": "task",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "turn_on",
      "label": null,
      "name": "task",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
