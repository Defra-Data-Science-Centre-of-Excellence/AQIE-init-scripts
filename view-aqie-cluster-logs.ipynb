{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f406666d-a567-4813-a288-9a0a4e4efc05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# View AQIE Shared cluster logs\n",
    "**Author:** Joseph Grealy   \n",
    "**Date of last update:** 21/09/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4f30b69-99a0-4b63-ae42-9b82d63b8e22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "We have added logging to the AQIE cluster. This is really useful, as it allows us to troubleshoot any failures in the cluster. However, the logs for the cluster are saved to the DBFS and can quickly grow to a huge number of files. There is an automated notebook set up to clean the logs every weekend, removing anything over 28 days old. But that still leaves quite a few logs to deal with. The code below pulls the latest log, and then prints the stdout and stderr outputs to troubleshoot any issues. \n",
    "\n",
    "\n",
    "The cluster ID for the farming stats cluster is **0920-173430-gsso5zn0**.\n",
    "\n",
    "The cluster logs are saved in the dbfs here: **/dbfs/cluster-logs/0920-173430-gsso5zn0**. There are four directories in this folder:\n",
    "\n",
    "* driver\n",
    "* eventlog\n",
    "* executer\n",
    "* init_scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bba9d407-fcd8-4a0d-89b0-0b5402da4a97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## How to use\n",
    "\n",
    "To use the **Code** to pull the latest log, do the following:\n",
    "\n",
    "1. Connect to any cluster to run this notebook - it does not need to be the team cluster (you can do this in the top right of the screen). \n",
    "2. The code chunk below will find the latest init script logs folder and print the outputs - the timestamp the log was generated is at the top of the output.\n",
    "\n",
    "If you wish to explore different logs, follow the **Additional Code** chunks below which are modified from the farming stats team's code.\n",
    "\n",
    "1. Run the first code chunk. This will output a list of files and the date they were modified. Find the desired file and copy the file name.\n",
    "2. Paste the file name into the second and third code chunks after **/dbfs/cluster-logs/0920-173430-gsso5zn0/init_scripts/**. \n",
    "3. Now run the second code chunk. In the output, ID the relevant stdout.log and stferr.log files and copy the file names.\n",
    "4. Paste these final names into the third code chunk after the final **/** (and after the code you updated in step 2), then run the third code chunk.\n",
    "5. This will output the contents of the log for you to examine. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1db50a96-05c1-4c37-aeb5-5d7140ed9306",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9739d8c-2fc3-46a5-bf49-1540ba0f04ff",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Get latest init script log paths and print"
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "LOG_BASE=\"/dbfs/cluster-logs/0920-173430-gsso5zn0/init_scripts\"\n",
    "\n",
    "# Function to find the latest log of a given type\n",
    "find_latest_log() {\n",
    "    local pattern=\"$1\"\n",
    "    find \"$LOG_BASE\" -type f -name \"$pattern\" | \\\n",
    "    awk -F'/' '{\n",
    "        # extract filename\n",
    "        n = split($NF, a, \"_\")\n",
    "        # timestamp is first two parts: YYYYMMDD_HHMMSS\n",
    "        timestamp = a[1] a[2]\n",
    "        print timestamp, $0\n",
    "    }' | sort -nr | head -1 | awk '{print $2}'\n",
    "}\n",
    "\n",
    "LATEST_STDOUT=$(find_latest_log \"*.stdout.log\")\n",
    "LATEST_STDERR=$(find_latest_log \"*.stderr.log\")\n",
    "\n",
    "echo \"Latest stdout log: $LATEST_STDOUT\"\n",
    "echo \"Latest stderr log: $LATEST_STDERR\"\n",
    "\n",
    "echo \"=== STDOUT ===\"\n",
    "cat \"$LATEST_STDOUT\"\n",
    "\n",
    "echo \"=== STDERR ===\"\n",
    "cat \"$LATEST_STDERR\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1fb8c18a-baa4-4989-81ae-f594ecc624e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Additional Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3149dbbb-094c-4cea-b8e4-3076b50144fe",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Find the latest log folder"
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "ls -hlt /dbfs/cluster-logs/0920-173430-gsso5zn0/init_scripts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5dd95012-0e12-48b0-bd67-85b4540dfe78",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "List the saved logs in that folder"
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "ls -hlt /dbfs/cluster-logs/0920-173430-gsso5zn0/init_scripts/0920-173430-gsso5zn0_66db271afd644efbb4436fcb57d8c4fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7ec2d02-fc56-4117-9f5e-b3a37f704e9d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Display the log"
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "cat /dbfs/cluster-logs/0920-173430-gsso5zn0/init_scripts/0920-173430-gsso5zn0_66db271afd644efbb4436fcb57d8c4fc/20250921_110317_00_general-init-script.sh.stdout.log"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5632569287098634,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "view-aqie-cluster-logs",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
